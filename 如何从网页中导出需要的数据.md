# 如何从网页中导出需要的数据

最近，由于做文献调研，需要统计一些成分数据。经过搜索，我找到了一个在线数据库。但这个数据库不提供全文下载，为了能够下载数据并快速批量搜索数据库中的内容。我用python写了一段代码，用于自动下载网页文件并导出需要数据到Excel。

以下是代码说明：

## 一、网页下载

观察后发现，网页链接是由前缀和数字组成的形如，https://xxxx./xxxxx.php?id=num,所以，将通过循环语句来完成下载

```Python
import urllib.request#导入插件
 
#定义函数读取链接
def getHtml(url):
    html = urllib.request.urlopen(url).read() #调用urllib读取链接
    return html

#定义函数保存网页
def saveHtml(file_name, file_content):
    #注意windows文件命名的禁用符，比如 /
    with open(file_name.replace('/', '_') + ".html", "wb") as f:
        #写文件用bytes而不是str，所以要转码
        f.write(file_content)

#设定参数i，i为需要下载的网页数量
i = 1
for i in range(1,707):
    aurl = "https://xxxx/xxxx.php?id=" + str(i) #组合形成网页url
    html = getHtml(aurl)#调用函数读取链接到html字符串
    name = "文件" + str(i)#组合形成文件名
    saveHtml(name, html)#调用函数保存下载链接
    i += 1

print('下载成功')
```

## 二、网页内容分析

网页共700个，网页下载下来后，需要进行数据分析提取。为了便于筛选和对比，我决定导出到excel比较方便。

根据分析网页内容，发现需要提取的内容都是被td标签所标记的，并且数值总在参量名的下一项，如下所示。

```html
	<td class="lt t">软磁性能</td>
						<td class="lt">有效磁导率</td>
						<td>11.00</td>
						<td></td>
```

所以，我决定调用bs4和pandas库来完成这项工作。

```python

from bs4 import BeautifulSoup
import lxml
import requests
import pandas as pd
import numpy as np

#定义读取网页文件的函数
def read_html(path):           #读取单个html到pd
    htmlfile = open(path, 'r', encoding='utf-8')#打开地址所在的网页文件
    htmlhandle = htmlfile.read()#读取该网页文件全文到htmlhandle
    soup = BeautifulSoup(htmlhandle, 'lxml')#调用BeautifulSoup读取网页标签内容
    td_list = soup.find_all('td')  # 找到所有td标签
    
    #创建三个列表，temporary是临时列表，result是用来存放带有td标签内容的列表，final是我们最终导出的列表
    result = []
    final = []
    temporary = []
    
    #将所有的td标签中的值导入result列表中
    for d in td_list:
        #print(d.string)#实时输出读取的值
        result.append(d.string) #实时将值保存到列表

   
    print(len(result)) #输出result项目数
    
    t = 0#创建顺序参量t，确保所有标签都被遍历
    for t in range(len(result)):
        if  result[t] != None:#确保标签不是空，防止程序报错
           if  result[t] == '类型':#比对标签内容，如果相同就打印下一项（参数）
                print(result[t+1])
                temporary.append(result[t+1])#将下一项添加到临时列表的最后
    #如果临时列表不为零，则将临时列表的内容添加到final列表，否则就在final列表中添加‘无’，确保最终参数顺序不会错
    if len(temporary) != 0:
        final.extend(temporary)
    else:
        final.append('无')

    t = 0
    temporary = []#将临时列表清零
    for t in range(len(result)):
        if  result[t] != None:
           if  result[t] == '成份配比':
                print(result[t+1])
                temporary.append(result[t+1])
    if len(temporary) != 0:
        final.extend(temporary)
    else:
        final.append('无')
                
    t = 0
    temporary = []
    for t in range(len(result)):
        if  result[t] != None:
           if  result[t] == '饱和磁感应强度(T)':
                print(result[t+1]+'T')
                temporary.append(result[t+1]+'T')
    if len(temporary) != 0:
        final.extend(temporary)
    else:
        final.append('无')

    t = 0
    temporary = []
    for t in range(len(result)):
        if  result[t] != None:
           if  result[t] == '矫顽力':
                print(result[t+1]+'A/m')
                temporary.append(result[t+1]+'A/m')
    if len(temporary) != 0:
        final.extend(temporary)
    else:
        final.append('无')

    t = 0
    temporary = []
    for t in range(len(result)):
        if  result[t] != None:
           if  result[t] == '有效磁导率':
                print(result[t+1])
                temporary.append(result[t+1])
    if len(temporary) != 0:
        final.extend(temporary)
    else:
        final.append('无')

    t = 0
    temporary = []
    for t in range(len(result)):
        if  result[t] != None:
           if  result[t] == '热处理温度':
                print(result[t+1])
                temporary.append(result[t+1]+'℃')
    if len(temporary) != 0:
        final.extend(temporary)
    else:
        final.append('无')

    t = 0
    temporary = []
    for t in range(len(result)):
        if  result[t] != None:
           if  result[t] == '热处理时间':
                print(result[t+1])
                temporary.append(result[t+1]+'min')
    if len(temporary) != 0:
        final.extend(temporary)
    else:
        final.append('无')

    t = 0
    temporary = []
    for t in range(len(result)):
        if  result[t] != None:
           if  result[t] == '出处':
                print(result[t+1])
                temporary.append(result[t+1])
    if len(temporary) != 0:
        final.extend(temporary)
    else:
        final.append('无')


    df = pd.DataFrame(final)#将final转化为panda数据帧
    return df                     #返回参数


path = './文件1.html'#初始文件路径
df1 = read_html(path)                #调用函数

number = 700#需要读取的文件数目

for i in range(2,number):#循环读取余下文件，其中组合参数名使用locals()函数来创建
    path = "./文件" + str(i) +".html"
    locals()['df'+str(i)]= read_html(path)#循环创造dfn函数
    i += 1

writer = pd.ExcelWriter('./stat.xlsx', engine='xlsxwriter') #创建excel文件,注意路径中的数/,与windows中的\不同

df1.to_excel(writer, sheet_name='Sheet1')  # 起始写入位置, A1列.

for i in range(2,number):#利用local()批量调用刚才创建的函数
    locals()['df'+str(i)].to_excel(writer, sheet_name='Sheet1', startcol=i,index=None,header=True)
    i += 1

writer.save() #保存文件

print("全部信息爬取完毕，请查看Excel文件")
```

导出后，可以得到纵向排列的数据，然后，结合excel整理便得到了所需的数据。